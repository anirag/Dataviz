{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6062ebf7-8e27-423f-9601-70b513d906c4",
    "_execution_state": "busy",
    "_uuid": "644fe876d41b25011a0dc309f5cdee9f8c467698",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1b031c59-a5db-425d-9a03-be940c876c67",
    "_execution_state": "busy",
    "_uuid": "16fb6cfb0b94d305d3b773febf4a1649534d0748",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/Downloads/abcnews-date-text.csv\",error_bad_lines=False,warn_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3925eef5-7e44-49e2-ac77-d1f5e485aaf8",
    "_execution_state": "busy",
    "_uuid": "b9c003574b4dc81f157036e4a76141926610dfb0",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a04f99be-fb3e-4bb1-b64c-799741987508",
    "_execution_state": "busy",
    "_uuid": "e5fe1dc63c9c1f6baec33c82dc52ac8935104851",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.publish_date = pd.to_datetime(df.publish_date,format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1ba89a6-f293-47f5-9bd9-9af6480c5365",
    "_execution_state": "busy",
    "_uuid": "fdcc5e5d313bf778ee98668f5a69b599422a3a3d",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.publish_date.min(),df.publish_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4c78c741-ff43-4959-b4c6-f6ffb6a7f9a4",
    "_execution_state": "busy",
    "_uuid": "f039e4cd1d2e7c6db4093bd22a17312c4411941b",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.publish_date.max() - df.publish_date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1ae6bee2-c9be-49cf-98dd-54e3700ed6cf",
    "_execution_state": "busy",
    "_uuid": "262a3700e0a2b05e2d560fc823ffd1438a1032bd",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df.publish_date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = df.groupby('publish_date').tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_headlines = s.headline_text.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c4069cab-af9e-4ad2-b8bb-1cbd38b1506b",
    "_execution_state": "idle",
    "_uuid": "cb277662e5329419f42d51d204fc885d96132e27",
    "collapsed": false
   },
   "source": [
    "## Get the sentiment for each headline and list positive , negative and neutral headlines separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5963aa2c-ee72-4d3a-a22a-cf3277a1374f",
    "_execution_state": "busy",
    "_uuid": "b80a32e84e44cecadb4f78d1bd2e3e14339c38b5",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from nltk.corpus import stopwords\n",
    "StopWords = stopwords.words(\"english\")\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "94568261-26a5-4c77-b60e-57c6bca00291",
    "_execution_state": "busy",
    "_uuid": "78048e18a56828ea2bb96899c7e7d7d4fc1b2c28",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sia = SIA()\n",
    "pos_list = []\n",
    "neg_list = []\n",
    "neu_list = []\n",
    "for post in all_headlines:\n",
    "    post = \" \".join([stemmer.stem(word) for word in str(post).lower().split() if word not in set(StopWords)])\n",
    "    res = sia.polarity_scores(post)\n",
    "    if res['compound'] > 0.0:\n",
    "        pos_list.append(post)\n",
    "    elif res['compound'] < 0.0:\n",
    "        neg_list.append(post)\n",
    "    else:\n",
    "        neu_list.append(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "755bd5ef-88fa-4a8e-9919-620c5ee6ad9d",
    "_execution_state": "busy",
    "_uuid": "7561c2329d0b414e1c90589d1172181e9efaeceb",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of Positive Headlines : {}\\nNumber of Negative Headlines : {}\\nNumber of Neutral Headlines : {}\".format(len(pos_list),len(neg_list),len(neu_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b99587cd-5d80-4625-bc3d-1493111bb049",
    "_execution_state": "busy",
    "_uuid": "5dc383b2550541d12a4f4d4f0c2d331e0a7763f6",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "76056268-426c-4c99-bb84-040753cdc6ec",
    "_execution_state": "busy",
    "_uuid": "11c55ec3bf2e2530e42a1ea9b199c0f2b3564978",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_words = []\n",
    "for line in pos_list:\n",
    "    words = tokenizer.tokenize(line)\n",
    "    for w in words:\n",
    "        pos_words.append(w.lower())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "36814346-fc19-4c7d-ac97-c14b45285630",
    "_execution_state": "busy",
    "_uuid": "4af8981bebba0c11251e929b660077e2c2e0726e",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_words = []\n",
    "for line in neg_list:\n",
    "    words = tokenizer.tokenize(line)\n",
    "    for w in words:\n",
    "        neg_words.append(w.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e28b453a-dc34-4749-85cb-5c8d8e5df9e2",
    "_execution_state": "idle",
    "_uuid": "c838b5739fa83129665da1bb8bdd319468b24465",
    "collapsed": false
   },
   "source": [
    "## Most common positive words in the headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f348777d-f062-46aa-bf17-ea5f4f0bee86",
    "_execution_state": "busy",
    "_uuid": "42dce2fdad24f0675a60111bf070eb285f1678a3",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "pos_words = FreqDist(pos_words)\n",
    "for x in pos_words.most_common(10):\n",
    "    print(x[0],\":\",x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e7f2cfcd-99e7-4f37-9a0f-c61d2ba91f56",
    "_execution_state": "idle",
    "_uuid": "79d649632fb9b875ba2049e22207faae25134c3b",
    "collapsed": false
   },
   "source": [
    "## Most common negative words in the headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a070d82f-3784-4ffc-a145-30298a05817d",
    "_execution_state": "busy",
    "_uuid": "178e2b673aefea37b45760a83e5346dc750af31c",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_words = FreqDist(neg_words)\n",
    "for x in neg_words.most_common(10):\n",
    "    print(x[0],\":\",x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5a68a97e-84ad-4a8d-ac03-89865d908656",
    "_execution_state": "idle",
    "_uuid": "1c8749d2038a4737bb5c91d58a6bdda4ee39523f",
    "collapsed": false
   },
   "source": [
    "## Distribution of words in Positive Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6337f7ba-bd0d-4668-9f58-dbef309bbe6b",
    "_execution_state": "busy",
    "_uuid": "c7286e787617d651732043a31436bfa1ca3f547a",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['xtick.labelsize'] = 14\n",
    "plt.figure(figsize=(20,10))\n",
    "pos_words.plot(50,cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4d650270-f9c3-45eb-b915-2051ae255e40",
    "_execution_state": "idle",
    "_uuid": "cf84e00895c88995603e8089701a60649f3381b2",
    "collapsed": false
   },
   "source": [
    "## Distribution of words in Negative Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2bc8276-1108-4f83-84d0-89c75e49cf7d",
    "_execution_state": "busy",
    "_uuid": "6488a404534820983e6e280bb7ea70cb1de3e52e",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "neg_words.plot(50,cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dd2d5c75-6653-48e0-80bb-d49d0b68ab39",
    "_execution_state": "idle",
    "_uuid": "98ba92344e829359cee851af5822535e9184e9bb",
    "collapsed": false
   },
   "source": [
    "####  The distribution is as expected, few words repeated most of the times in both positive and negative headlines. The frequency in case of Positive words dips quickly than Negative words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dba8a2eb-e5b4-4fd7-ad1e-3d4ef3deae62",
    "_execution_state": "idle",
    "_uuid": "00f25673e4394bde381f1f33282a083039df057f",
    "collapsed": false
   },
   "source": [
    "## NEXT UP : CLUSTERING INTO TOPICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ae820b38-9348-4760-8f19-061af7d4ea4b",
    "_execution_state": "busy",
    "_uuid": "20afad7fdcb9a45165fe6dfe7077fbc8e6d251aa",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = pos_list+neg_list+neu_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load gensim package for LDA and create a document-term matrix out of the headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e529aa99-6676-4168-9d96-817104b281dd",
    "_execution_state": "busy",
    "_uuid": "5614f9d7d2a14ce6b22a9c0327d637877e42b815",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "sample_clean = [text.split() for text in sample] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e0b693f7-ab27-4be4-bbcb-ee8a62e852a3",
    "_execution_state": "busy",
    "_uuid": "cf71c03594ba5c5539b38c186d4732892cbb4cc6",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(sample_clean)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in sample_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a LDA model for the document-term matrix, number of topics is set to be 10. \n",
    "### If you have only few documents increasing passes might help and if the documents are small (sparse) increasing iterations should help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "181af15c-b37f-4075-b7f0-f5a3a821a0a7",
    "_execution_state": "busy",
    "_uuid": "233cca7e8fb392615cca4fa8c14a3c0dbc3b566d",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "num_topics = 10\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=num_topics, id2word = dictionary, passes=50,iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Document-Topic distribution and Topic-Word distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtm = ldamodel.get_document_topics(doc_term_matrix)\n",
    "K = ldamodel.num_topics\n",
    "topic_word_matrix = ldamodel.print_topics(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The topics are: \\n\")\n",
    "for x in topic_word_matrix:\n",
    "    print(x[0],\":\",x[1],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the document-topic matrix for t-SNE visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import matutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "document_topic_matrix = matutils.corpus2dense(corpus=dtm,num_docs=len(all_headlines),num_terms=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = document_topic_matrix.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# a t-SNE model\n",
    "# angle value close to 1 means sacrificing accuracy for speed\n",
    "# pca initializtion usually leads to better results \n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0,init='pca',)\n",
    "\n",
    "# 8-D -> 2-D\n",
    "tsne_lda = tsne_model.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_lda_keys = []\n",
    "for i in range(a.shape[0]):\n",
    "    _lda_keys.append(a[i].argmax())\n",
    "len(_lda_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bokeh to plot a interactive-visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bokeh.plotting as bp\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import show\n",
    "\n",
    "# 10 colors\n",
    "colormap = np.array([\"#1f77b4\", \"#aec7e8\", \"#ff7f0e\", \"#ffbb78\", \"#2ca02c\",\"#98df8a\", \"#d62728\", \"#ff9896\",\"#bcbd22\", \"#dbdb8d\"])\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_lda = bp.figure(plot_width=1000, plot_height=1000,\n",
    "                     title=\"LDA t-SNE Viz\",\n",
    "                     tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
    "                     x_axis_type=None, y_axis_type=None, min_border=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = len(a)\n",
    "plot_lda.scatter(x=tsne_lda[:, 0], y=tsne_lda[:, 1],\n",
    "                 color=colormap[_lda_keys][:n],\n",
    "                 source=bp.ColumnDataSource({\n",
    "                   \"content\": sample_clean[:n],\n",
    "                   \"topic_key\": _lda_keys[:n]\n",
    "                   }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate the graph with words from each topic. Below we are just setting the coordinats for the text and get the word distribution form topic-word matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_summaries = [x[1] for x in topic_word_matrix]\n",
    "topic_coord = np.empty((a.shape[1], 2)) * np.nan\n",
    "for topic_num in _lda_keys:\n",
    "    topic_coord[topic_num] = tsne_lda[_lda_keys.index(topic_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add topic words to graph\n",
    "for i in range(a.shape[1]):\n",
    "    plot_lda.text(topic_coord[i, 0], topic_coord[i, 1], [topic_summaries[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show(plot_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The plot is really messy, reason should definitely be LDA model.. Each topic consist of similar words like \"world\",\"women\",\"australia\"..  For documents, the probablity of even most probable topic is also really low. Model can't distinguish documents into topics. Using more documents and tuning parameters should help."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
